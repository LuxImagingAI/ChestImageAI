{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2568e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import cv2\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a235842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../utils/')\n",
    "sys.path.append('/home/users/jsoelter/Code/big_transfer/')\n",
    "\n",
    "import data_loader, evaluations, model_setup, sacred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_utils\n",
    "import multi_head_modules as multihead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4593f",
   "metadata": {},
   "source": [
    "### Pretrained setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc79db",
   "metadata": {},
   "source": [
    "Load a pretrained (biased) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = '/home/users/jsoelter/models/rsna/bitm/new_exp/mixed_15000_1_5_it1/step00464.pt'\n",
    "\n",
    "dirname = os.path.dirname(model_checkpoint)\n",
    "ledger = json.load(open(os.path.join(dirname, 'train_ledger.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d181ff0",
   "metadata": {},
   "source": [
    "### Parameter managment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d9fd5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "defaults = {} # default parameter, will be overwritten if set explicilty in this notebooke\n",
    "overwrites = {} # parameter that OVERWRITE all parameters set in this notebook. Usefull if Notebook is executed externally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pretrain = sacred.ParameterStore(defaults=ledger['train_setup']['0']['setup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65108d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sacred.ParameterStore(overwrites=overwrites, defaults=defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4de703",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c90c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f216db",
   "metadata": {},
   "source": [
    "#### Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50177060",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pretrain.model_dict['pretrained'] = model_checkpoint\n",
    "p_pretrain.model_dict['fresh_head_weights'] = False\n",
    "\n",
    "model = model_setup.instantiate_model(**p_pretrain.model_dict)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf62d9",
   "metadata": {},
   "source": [
    "#### Deconfounder Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5800fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.deconfounder_head = {\n",
    "    'features': {\n",
    "        'link_layers': ['head.avg'], \n",
    "        'out_channels': [6144]\n",
    "    },\n",
    "    'model': {\n",
    "        'class_name': 'multihead.ClassificationHead',\n",
    "        'param_dict': {}\n",
    "}}\n",
    "\n",
    "feature_extractor = multihead.FeatureExtractor(backbone=model)\n",
    "deconfounder = multihead.AttachedHead(feature_extractor, p.deconfounder_head)\n",
    "_ = deconfounder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.computation = {\n",
    "    'model_out': '/home/users/jsoelter/models/rsna/bitm/new_exp/deconf_test',\n",
    "}\n",
    "\n",
    "if not os.path.exists(p.computation['model_out']):\n",
    "    os.makedirs(p.computation['model_out'])\n",
    "\n",
    "saved_models = glob.glob(os.path.join(p.computation['model_out'], 'step*.pt'))\n",
    "if not saved_models:\n",
    "    checkpoint = None\n",
    "    ledger = collections.defaultdict(list)\n",
    "    step = 0\n",
    "else:\n",
    "    last_model = np.sort(saved_models)[-1]\n",
    "    print(f\"Resume training for saved model '{last_model}'\")\n",
    "    checkpoint = torch.load(last_model, map_location=\"cpu\")\n",
    "    re_keyed = {k.split('module.')[-1]: v for k, v in checkpoint['model'].items()}\n",
    "    model.load_state_dict(re_keyed)\n",
    "    \n",
    "    ledger = json.load(open(os.path.join(p.computation['model_out'], 'train_ledger.json')))\n",
    "    step = checkpoint[\"step\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf2762",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b2b05",
   "metadata": {},
   "source": [
    "#### Data Setup of Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca583462",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.data_setup = copy.deepcopy(p_pretrain.data_setup)\n",
    "p.data_setup = {\n",
    "    'data': { \n",
    "        'include_meta_features': ['Sex']\n",
    "}}\n",
    "p.sampling_config = copy.deepcopy(p_pretrain.sampling_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3360bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.data_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa31e47",
   "metadata": {},
   "source": [
    "#### Y-independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.data_setup['data_y0'] = {\n",
    "    'include_meta': [], \n",
    "    'include_meta_features': ['Sex'],\n",
    "    'subset': {\n",
    "        'Target': [0]\n",
    "    },\n",
    "    'val_conf': p.data_setup['data']['val_conf'].copy()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc0989c",
   "metadata": {},
   "source": [
    "#### Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = data_loader.transform_pipeline_from_dict(p.data_setup['transforms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf3b42",
   "metadata": {},
   "source": [
    "#### Datasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf2d37",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_data = data_loader.RSNAPneumoniaData(\n",
    "    transform=preprocess, \n",
    "    sub_sampling = p.sampling_config, \n",
    "    validation=False,  \n",
    "    datapath = '/work/projects/covid19_dv/raw_data/rsna_pneunomia/', \n",
    "    **p.data_setup['data']\n",
    ")\n",
    "\n",
    "valid_data = data_loader.RSNAPneumoniaData(\n",
    "    transform=preprocess, \n",
    "    sub_sampling=p.sampling_config, \n",
    "    validation=True,\n",
    "    datapath = '/work/projects/covid19_dv/raw_data/rsna_pneunomia/', \n",
    "    **p.data_setup['data']                                    \n",
    ")\n",
    "\n",
    "train_data_y0 = data_loader.RSNAPneumoniaData(\n",
    "    transform=preprocess, \n",
    "    sub_sampling=p.sampling_config, \n",
    "    validation=False,\n",
    "    datapath = '/work/projects/covid19_dv/raw_data/rsna_pneunomia/',                                       \n",
    "    **p.data_setup['data_y0']\n",
    ")\n",
    "\n",
    "valid_data_y0 = data_loader.RSNAPneumoniaData(\n",
    "    transform=preprocess,\n",
    "    sub_sampling=p.sampling_config,\n",
    "    validation=True, \n",
    "    datapath = '/work/projects/covid19_dv/raw_data/rsna_pneunomia/',                                       \n",
    "    **p.data_setup['data_y0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f75c0e",
   "metadata": {},
   "source": [
    "####  External Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_sampling = {\n",
    "    'meta_field': 'Sex',\n",
    "    'meta_values': ['M', 'F'],\n",
    "    'frac_meta0': 0.5,\n",
    "    'frac_meta0_tar1': 0.3,\n",
    "    'frac_meta1_tar1': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84102045",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_loader.RSNAPneumoniaData(\n",
    "    transform=preprocess, \n",
    "    sub_sampling=testset_sampling, \n",
    "    validation=True,\n",
    "    datapath = '/work/projects/covid19_dv/raw_data/rsna_pneunomia/', \n",
    "    **p.data_setup['data']                                    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05e65e",
   "metadata": {},
   "source": [
    "## Deconfounder Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6b66b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3856b2",
   "metadata": {},
   "source": [
    "#### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6506f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "computational_setup = dict(\n",
    "    num_workers = 8,\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, **computational_setup)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, **computational_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6dbd53",
   "metadata": {},
   "source": [
    "#### Function to do validation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321599ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_prediction(head, loader, max_batch=-1, tta_ensemble = 1, device=None):\n",
    "    \n",
    "    head.eval()\n",
    "    device = device or torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ensemble, targets, meta = [], [], []\n",
    "    for i in range(tta_ensemble):\n",
    "        preds, targs, metas = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for i, (x, t, m) in enumerate(loader):\n",
    "                x, m = x.to(device), m.numpy()\n",
    "                logits = head(x)\n",
    "                preds.append(logits.to('cpu').numpy())\n",
    "                meta.append(m)\n",
    "                targs.append(t)\n",
    "                if i == max_batch:\n",
    "                    break\n",
    "\n",
    "        ensemble.append(np.vstack(preds))\n",
    "        targets.append(np.vstack(targs))\n",
    "        metas.append(np.vstack(meta))\n",
    "   \n",
    "    return np.array(ensemble).squeeze(), targets[0], metas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c3c71",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02665047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets, meta = batch_prediction(deconfounder, test_loader, device=device)    \n",
    "print(f'AUC M vs F: {skm.roc_auc_score(meta>0, preds.reshape(-1, 1)):.3f}')\n",
    "preds, targets, meta = batch_prediction(model, test_loader, device=device)    \n",
    "print(f'AUC ext.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')\n",
    "preds, targets, _ = batch_prediction(model, valid_loader, device=device)\n",
    "print(f'AUC int.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050a5c8",
   "metadata": {},
   "source": [
    "### Confounder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_confounder_head(model, data_iter, optimizer, device=device):\n",
    "    \n",
    "    x, y, m = next(data_iter)\n",
    "    # Schedule sending to GPU(s)\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    m = (m>0).float().to(device, non_blocking=True)\n",
    "\n",
    "    # update confounder prediction\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(x)            \n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(logits, m)\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "        \n",
    "    return float(loss.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef453ea9",
   "metadata": {},
   "source": [
    "#### Confounder Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832fce6",
   "metadata": {},
   "source": [
    "Optimizer to train confounder head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541209fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.opt_conf = {\n",
    "    'class': 'SGD',\n",
    "    'param': dict(\n",
    "        lr = 1E-4,\n",
    "        momentum=0.9,\n",
    "        nesterov = True\n",
    "    )\n",
    "}\n",
    "\n",
    "optim_conf = getattr(torch.optim, p.opt_conf['class'])(deconfounder.head.parameters(), **p.opt_conf['param'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b9266",
   "metadata": {},
   "source": [
    "#### Y-restricted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "computational_setup_conf = dict(\n",
    "    num_workers = 8,\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "valid_y0_loader = torch.utils.data.DataLoader(valid_data_y0, **computational_setup_conf)\n",
    "\n",
    "train_y0_loader = torch.utils.data.DataLoader(train_data_y0, **computational_setup_conf)\n",
    "train_y0_iter = train_utils.EndlessIterator(train_y0_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4ab59",
   "metadata": {},
   "source": [
    "#### Train confounder head for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "current_epoch = train_y0_iter.epochs\n",
    "finish_epoch = current_epoch + num_epochs\n",
    "\n",
    "losses = []\n",
    "steps = 0\n",
    "while current_epoch < finish_epoch:\n",
    "    loss = train_step_confounder_head(deconfounder, train_y0_iter, optim_conf)\n",
    "    losses.append(loss)\n",
    "    steps += 1\n",
    "    if train_y0_iter.epochs != current_epoch:\n",
    "        current_epoch = train_y0_iter.epochs\n",
    "        preds, targets, meta = batch_prediction(deconfounder, test_loader, device=device)\n",
    "        auc = evaluations.eval_auc(preds.reshape(-1, 1), meta>0)\n",
    "        print(f'Train: {np.mean(losses):.2f}, AUC: {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets, meta = batch_prediction(deconfounder, test_loader, device=device)    \n",
    "print(f'AUC M vs F: {skm.roc_auc_score(meta>0, preds.reshape(-1, 1)):.3f}')\n",
    "preds, targets, meta = batch_prediction(model, test_loader, device=device)    \n",
    "print(f'AUC ext.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')\n",
    "preds, targets, _ = batch_prediction(model, valid_loader, device=device)\n",
    "print(f'AUC int.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbabc54",
   "metadata": {},
   "source": [
    "### Deconfounding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa381f41",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "computational_setup_deconf = dict(\n",
    "    num_workers = 8,\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, **computational_setup_deconf)\n",
    "train_iter = train_utils.EndlessIterator(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, deconfounder, data_iter, optimizer, batch_acc=1, alpha=0.5, meta_injection=False, device=device):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    for i in range(batch_acc):\n",
    "        \n",
    "        x, y, m = next(data_iter)\n",
    "        # Schedule sending to GPU(s)\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        \n",
    "        # select y restricted data\n",
    "        y_restriction = y == 0\n",
    "        # skip update if \n",
    "        if y_restriction.sum() < 2:\n",
    "            continue\n",
    "        m = (m>0).float().to(device, non_blocking=True)\n",
    "\n",
    "        # update predictor\n",
    "        logits_pred = model(x)\n",
    "        loss_pred = torch.nn.functional.binary_cross_entropy_with_logits(logits_pred, y)\n",
    "        \n",
    "        logits_conf = deconfounder()[y_restriction] \n",
    "        targets_conf = m[y_restriction]\n",
    "\n",
    "        loss_conf = torch.abs(\n",
    "            torch.nn.functional.cosine_similarity(\n",
    "                logits_conf - logits_conf.mean(), \n",
    "                targets_conf - targets_conf.mean(), \n",
    "                dim=0))\n",
    "        \n",
    "        #loss_conf = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        #    logits_conf.squeeze(), \n",
    "        #    0.5*torch.ones_like(logits_conf.squeeze())\n",
    "        #)\n",
    "    \n",
    "        loss_full = loss_pred + alpha*loss_conf\n",
    "        (loss_full/batch_acc).backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.opt_deconf = {\n",
    "    'class': 'SGD',\n",
    "    'param': dict(\n",
    "        lr = 1E-4,\n",
    "        momentum=0.5,\n",
    "        nesterov = False\n",
    "    )\n",
    "}\n",
    "\n",
    "optim_pred = getattr(torch.optim, p.opt_deconf['class'])(model.parameters(), **p.opt_deconf['param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ee00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_acc = 4\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5b1a5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "modulo = 1\n",
    "\n",
    "step = 0\n",
    "\n",
    "train_setup = ledger.setdefault('train_setup', {})\n",
    "train_setup[step] = {\n",
    "    'setup': p.params,\n",
    "}\n",
    "\n",
    "_ = model.train()\n",
    "while step < max_steps:\n",
    "    \n",
    "    step += 1\n",
    "    \n",
    "    # train target + deconfounding\n",
    "    for i in range(50):\n",
    "        train_step(model, deconfounder, train_iter, optim_pred, batch_acc = batch_acc, alpha=alpha)\n",
    "    \n",
    "    if steps % modulo == 0:\n",
    "        preds, targets, meta = batch_prediction(deconfounder, test_loader, device=device)    \n",
    "        print(f'AUC M vs F: {skm.roc_auc_score(meta>0, preds.reshape(-1, 1)):.3f}')\n",
    "        preds, targets, meta = batch_prediction(model, test_loader, device=device)    \n",
    "        print(f'AUC ext.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')\n",
    "        preds, targets, _ = batch_prediction(model, valid_loader, device=device)\n",
    "        print(f'AUC int.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')\n",
    "    \n",
    "    # train confounder head\n",
    "    for i in range(200):    \n",
    "        train_step_confounder_head(deconfounder, train_y0_iter, optim_conf)\n",
    "\n",
    "    if steps % modulo == 0:\n",
    "        preds, targets, meta = batch_prediction(deconfounder, test_loader, device=device)    \n",
    "        print(f'AUC M vs F: {skm.roc_auc_score(meta>0, preds.reshape(-1, 1)):.3f}')\n",
    "        print('===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae62d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889e748",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac81eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cat((a,t[2].unsqueeze(2).unsqueeze(3).to('cuda')), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        \"step\": steps,\n",
    "        \"backbone\": model.state_dict(),\n",
    "        \"deconf_head\": deconfounder.head.state_dict(),\n",
    "        \"optim_model\": optim_pred.state_dict(),\n",
    "        \"optim_conf\" : optim_conf.state_dict(),\n",
    "    }, \n",
    "    os.path.join(p.computation['model_out'], f'step{step:05d}.pt')\n",
    ")\n",
    "json.dump(ledger, open(os.path.join(p.computation['model_out'], 'train_ledger.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463efa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets, meta = batch_prediction(deconfounder, test_loader, device=device)    \n",
    "print(f'AUC M vs F: {skm.roc_auc_score(meta>0, preds.reshape(-1, 1)):.3f}')\n",
    "preds, targets, meta = batch_prediction(model, test_loader, device=device)    \n",
    "print(f'AUC ext.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')\n",
    "preds, targets, _ = batch_prediction(model, valid_loader, device=device)\n",
    "print(f'AUC int.: {skm.roc_auc_score(targets, preds.reshape(-1, 1)):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c48bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
