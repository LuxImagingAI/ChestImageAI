{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import cv2\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/users/jsoelter/Code/ChestImageAI/utils/')\n",
    "sys.path.append('/home/users/jsoelter/Code/big_transfer/')\n",
    "\n",
    "import data_loader, evaluations, model_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict =  dict(\n",
    "    #architecture = 'BiT-M-R50x3',\n",
    "    architecture = 'densenet121',\n",
    "    num_classes = 5,\n",
    "    pretrained = 'imagenet', #'/home/users/jsoelter/models/chexpert/fullmeta_503/step05000.pt',\n",
    "    fresh_head_weights = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = '/home/users/jsoelter/models/chexpert/densenet/pain_lowres3'\n",
    "\n",
    "if not os.path.exists(model_out):\n",
    "    os.makedirs(model_out)\n",
    "\n",
    "model = model_setup.instantiate_model(**model_dict)\n",
    "\n",
    "saved_models = glob.glob(os.path.join(model_out, 'step*.pt'))\n",
    "if not saved_models:\n",
    "    checkpoint = None\n",
    "    ledger = collections.defaultdict(list)\n",
    "    ledger['model'] = model_dict\n",
    "    step = 0\n",
    "else:\n",
    "    last_model = np.sort(saved_models)[-1]\n",
    "    print(f\"Resume training for saved model '{last_model}'\")\n",
    "    checkpoint = torch.load(last_model, map_location=\"cpu\")\n",
    "    re_keyed = {k.split('module.')[-1]: v for k, v in checkpoint['model'].items()}\n",
    "    model.load_state_dict(re_keyed)\n",
    "    \n",
    "    ledger = json.load(open(os.path.join(model_out, 'train_ledger.json')))\n",
    "    step = checkpoint[\"step\"]\n",
    "\n",
    "    \n",
    "# Lets cuDNN benchmark conv implementations and choose the fastest.\n",
    "# Only good if sizes stay the same within the main loop!\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_setup = dict(\n",
    "    include_meta = [],\n",
    "    #include_meta = ['Sex', 'AP/PA', 'Frontal/Lateral'],\n",
    "    label_value_map = {\n",
    "       0: 0.05,\n",
    "       'nan': 0.1,\n",
    "       -1.: 0.5,\n",
    "       1: 0.9\n",
    "    },\n",
    "    fill_hierachy = {\n",
    "        #'Enlarged Cardiomediastinum': ['Cardiomegaly'],\n",
    "        #'Consolidation': ['Pneumonia'],\n",
    "        #'Lung Opacity': ['Edema', 'Pneumonia', 'Consolidation', 'Lung Lesion', 'Atelectasis']\n",
    "    },\n",
    "    labels = ['Cardiomegaly', 'Edema',  'Consolidation', 'Atelectasis', 'Pleural Effusion'],\n",
    "    subset = {}, # Define subsetting of data\n",
    ")\n",
    "\n",
    "transforms = [\n",
    "    ('ToPILImage', {}),\n",
    "    ('Resize', {\n",
    "        'size': 544\n",
    "    }),\n",
    "    ('RandomRotation', {\n",
    "        'degrees': 5\n",
    "    }),    \n",
    "    ('RandomCrop', {\n",
    "        'size': (512, 512)\n",
    "    }),\n",
    "    ('Resize', {\n",
    "        'size': 136 #smaller edege mapped to x\n",
    "    }),\n",
    "    ('ToTensor', {}),\n",
    "    ('Normalize', {\n",
    "        'mean': [0.485, 0.456, 0.406], #'mean': (0.5, 0.5, 0.5),\n",
    "        'std': [0.229, 0.224, 0.225]  #(0.5, 0.5, 0.5)\n",
    "    }),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 entries\n",
      "Removed 0 entries\n"
     ]
    }
   ],
   "source": [
    "preprocess = data_loader.transform_pipeline_from_dict(transforms)\n",
    "\n",
    "data = data_loader.ChexpertData('CheXpert-v1.0/train.csv', transform=preprocess, **data_setup)\n",
    "internal_valid_data, train_data = torch.utils.data.random_split(data, [1000, len(data)-1000], generator=torch.Generator().manual_seed(42))\n",
    "external_valid_data = data_loader.ChexpertData('CheXpert-v1.0/valid.csv', transform=preprocess, \n",
    "                                               labels=data_setup['labels'], include_meta=data_setup['include_meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6951.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_batch_size = 32#128\n",
    "batch_split = 1 #8 #number of forward pathes before optimization is performed \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=int(real_batch_size/batch_split), num_workers=8, shuffle=True, drop_last=False)\n",
    "\n",
    "valid_int_loader = torch.utils.data.DataLoader(internal_valid_data, batch_size=int(real_batch_size/batch_split), num_workers=8, shuffle=True)\n",
    "valid_ext_loader = torch.utils.data.DataLoader(external_valid_data, batch_size=16, num_workers=8)\n",
    "\n",
    "len(train_loader)/batch_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'Adam'#'SGD'\n",
    "opt_param = dict(\n",
    "    lr = 1E-4,\n",
    "    #momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optim = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "#optim = torch.optim.SGD([p for n,p in model.named_parameters() if 'head' in n], lr=0.003, momentum=0.9)\n",
    "optim = getattr(torch.optim, opt)(model.parameters(), **opt_param)\n",
    "if  checkpoint is not None:\n",
    "    optim.load_state_dict(checkpoint[\"optim\"])\n",
    "else:\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = [-1, len(train_loader), int(1.5*len(train_loader)), int(2*len(train_loader))]#[3000, 7000, 9000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on = None #['Cardiomegaly'] #,  'Consolidation' 'Cardiomegaly', 'Atelectasis', 'Pleural Effusion', 'Edema', 'Support Devices',  'AP/PA', 'Sex', 'Frontal/Lateral'] #,\n",
    "train_cols = [i in train_on for i in data.targets] if train_on else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = model_setup.maskedBCE(train_cols, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on None: 0.556\n",
      "Crit on None: 0.691\n"
     ]
    }
   ],
   "source": [
    "preds, targets = evaluations.batch_prediction(model, valid_ext_loader)\n",
    "print(f'AUC on {train_on}: {evaluations.eval_auc(preds, targets, train_cols):.3f}')\n",
    "print(f'Crit on {train_on}: {evaluations.eval_crit(model, valid_int_loader, crit):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_intervall = 50\n",
    "save_intervall = 3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50 ->, train: 0.592, val internal : 0.562, auc select: 0.731, auc bench: 0.731\n",
      "step 100 ->, train: 0.574, val internal : 0.551, auc select: 0.739, auc bench: 0.739\n",
      "step 150 ->, train: 0.512, val internal : 0.544, auc select: 0.750, auc bench: 0.750\n",
      "step 200 ->, train: 0.535, val internal : 0.547, auc select: 0.777, auc bench: 0.777\n",
      "step 250 ->, train: 0.608, val internal : 0.543, auc select: 0.769, auc bench: 0.769\n",
      "step 300 ->, train: 0.539, val internal : 0.542, auc select: 0.776, auc bench: 0.776\n",
      "step 350 ->, train: 0.502, val internal : 0.538, auc select: 0.798, auc bench: 0.798\n",
      "step 400 ->, train: 0.579, val internal : 0.538, auc select: 0.783, auc bench: 0.783\n",
      "step 450 ->, train: 0.520, val internal : 0.539, auc select: 0.807, auc bench: 0.807\n",
      "step 500 ->, train: 0.510, val internal : 0.536, auc select: 0.796, auc bench: 0.796\n",
      "step 550 ->, train: 0.526, val internal : 0.536, auc select: 0.783, auc bench: 0.783\n",
      "step 600 ->, train: 0.545, val internal : 0.534, auc select: 0.806, auc bench: 0.806\n",
      "step 650 ->, train: 0.533, val internal : 0.532, auc select: 0.812, auc bench: 0.812\n",
      "step 700 ->, train: 0.563, val internal : 0.534, auc select: 0.844, auc bench: 0.844\n",
      "step 750 ->, train: 0.565, val internal : 0.531, auc select: 0.836, auc bench: 0.836\n",
      "step 800 ->, train: 0.547, val internal : 0.529, auc select: 0.819, auc bench: 0.819\n",
      "step 850 ->, train: 0.522, val internal : 0.530, auc select: 0.817, auc bench: 0.817\n",
      "step 900 ->, train: 0.562, val internal : 0.530, auc select: 0.806, auc bench: 0.806\n",
      "step 950 ->, train: 0.529, val internal : 0.532, auc select: 0.849, auc bench: 0.849\n",
      "step 1000 ->, train: 0.558, val internal : 0.530, auc select: 0.810, auc bench: 0.810\n",
      "step 1050 ->, train: 0.495, val internal : 0.527, auc select: 0.838, auc bench: 0.838\n",
      "step 1100 ->, train: 0.523, val internal : 0.527, auc select: 0.801, auc bench: 0.801\n",
      "step 1150 ->, train: 0.539, val internal : 0.530, auc select: 0.822, auc bench: 0.822\n",
      "step 1200 ->, train: 0.510, val internal : 0.529, auc select: 0.812, auc bench: 0.812\n",
      "step 1250 ->, train: 0.495, val internal : 0.527, auc select: 0.847, auc bench: 0.847\n",
      "step 1300 ->, train: 0.515, val internal : 0.527, auc select: 0.827, auc bench: 0.827\n",
      "step 1350 ->, train: 0.526, val internal : 0.524, auc select: 0.818, auc bench: 0.818\n",
      "step 1400 ->, train: 0.567, val internal : 0.531, auc select: 0.792, auc bench: 0.792\n",
      "step 1450 ->, train: 0.533, val internal : 0.527, auc select: 0.828, auc bench: 0.828\n",
      "step 1500 ->, train: 0.531, val internal : 0.526, auc select: 0.822, auc bench: 0.822\n",
      "step 1550 ->, train: 0.568, val internal : 0.525, auc select: 0.832, auc bench: 0.832\n",
      "step 1600 ->, train: 0.541, val internal : 0.523, auc select: 0.824, auc bench: 0.824\n",
      "step 1650 ->, train: 0.544, val internal : 0.525, auc select: 0.834, auc bench: 0.834\n",
      "step 1700 ->, train: 0.507, val internal : 0.526, auc select: 0.829, auc bench: 0.829\n",
      "step 1750 ->, train: 0.529, val internal : 0.532, auc select: 0.807, auc bench: 0.807\n",
      "step 1800 ->, train: 0.532, val internal : 0.529, auc select: 0.838, auc bench: 0.838\n",
      "step 1850 ->, train: 0.525, val internal : 0.524, auc select: 0.822, auc bench: 0.822\n",
      "step 1900 ->, train: 0.578, val internal : 0.526, auc select: 0.808, auc bench: 0.808\n",
      "step 1950 ->, train: 0.542, val internal : 0.523, auc select: 0.824, auc bench: 0.824\n",
      "step 2000 ->, train: 0.531, val internal : 0.523, auc select: 0.814, auc bench: 0.814\n",
      "step 2050 ->, train: 0.539, val internal : 0.521, auc select: 0.855, auc bench: 0.855\n",
      "step 2100 ->, train: 0.524, val internal : 0.523, auc select: 0.820, auc bench: 0.820\n",
      "step 2150 ->, train: 0.495, val internal : 0.523, auc select: 0.836, auc bench: 0.836\n",
      "step 2200 ->, train: 0.573, val internal : 0.525, auc select: 0.825, auc bench: 0.825\n",
      "step 2250 ->, train: 0.535, val internal : 0.521, auc select: 0.834, auc bench: 0.834\n",
      "step 2300 ->, train: 0.587, val internal : 0.524, auc select: 0.842, auc bench: 0.842\n",
      "step 2350 ->, train: 0.529, val internal : 0.529, auc select: 0.805, auc bench: 0.805\n",
      "step 2400 ->, train: 0.485, val internal : 0.525, auc select: 0.773, auc bench: 0.773\n",
      "step 2450 ->, train: 0.520, val internal : 0.523, auc select: 0.840, auc bench: 0.840\n",
      "step 2500 ->, train: 0.549, val internal : 0.522, auc select: 0.840, auc bench: 0.840\n",
      "step 2550 ->, train: 0.497, val internal : 0.529, auc select: 0.821, auc bench: 0.821\n",
      "step 2600 ->, train: 0.493, val internal : 0.519, auc select: 0.814, auc bench: 0.814\n",
      "step 2650 ->, train: 0.522, val internal : 0.524, auc select: 0.809, auc bench: 0.809\n",
      "step 2700 ->, train: 0.543, val internal : 0.521, auc select: 0.845, auc bench: 0.845\n",
      "step 2750 ->, train: 0.566, val internal : 0.520, auc select: 0.856, auc bench: 0.856\n",
      "step 2800 ->, train: 0.515, val internal : 0.523, auc select: 0.814, auc bench: 0.814\n",
      "step 2850 ->, train: 0.576, val internal : 0.523, auc select: 0.822, auc bench: 0.822\n",
      "step 2900 ->, train: 0.553, val internal : 0.522, auc select: 0.828, auc bench: 0.828\n",
      "step 2950 ->, train: 0.524, val internal : 0.527, auc select: 0.798, auc bench: 0.798\n",
      "step 3000 ->, train: 0.498, val internal : 0.521, auc select: 0.817, auc bench: 0.817\n",
      "step 3050 ->, train: 0.562, val internal : 0.524, auc select: 0.826, auc bench: 0.826\n",
      "step 3100 ->, train: 0.550, val internal : 0.521, auc select: 0.857, auc bench: 0.857\n",
      "step 3150 ->, train: 0.487, val internal : 0.523, auc select: 0.844, auc bench: 0.844\n",
      "step 3200 ->, train: 0.492, val internal : 0.526, auc select: 0.816, auc bench: 0.816\n",
      "step 3250 ->, train: 0.501, val internal : 0.519, auc select: 0.832, auc bench: 0.832\n",
      "step 3300 ->, train: 0.521, val internal : 0.528, auc select: 0.801, auc bench: 0.801\n",
      "step 3350 ->, train: 0.484, val internal : 0.521, auc select: 0.822, auc bench: 0.822\n",
      "step 3400 ->, train: 0.554, val internal : 0.522, auc select: 0.819, auc bench: 0.819\n",
      "step 3450 ->, train: 0.520, val internal : 0.520, auc select: 0.844, auc bench: 0.844\n",
      "step 3500 ->, train: 0.575, val internal : 0.520, auc select: 0.850, auc bench: 0.850\n",
      "step 3550 ->, train: 0.513, val internal : 0.521, auc select: 0.830, auc bench: 0.830\n",
      "step 3600 ->, train: 0.517, val internal : 0.520, auc select: 0.842, auc bench: 0.842\n",
      "step 3650 ->, train: 0.507, val internal : 0.521, auc select: 0.815, auc bench: 0.815\n",
      "step 3700 ->, train: 0.534, val internal : 0.524, auc select: 0.806, auc bench: 0.806\n",
      "step 3750 ->, train: 0.556, val internal : 0.520, auc select: 0.855, auc bench: 0.855\n",
      "step 3800 ->, train: 0.521, val internal : 0.520, auc select: 0.827, auc bench: 0.827\n",
      "step 3850 ->, train: 0.504, val internal : 0.521, auc select: 0.848, auc bench: 0.848\n",
      "step 3900 ->, train: 0.519, val internal : 0.518, auc select: 0.835, auc bench: 0.835\n",
      "step 3950 ->, train: 0.537, val internal : 0.520, auc select: 0.847, auc bench: 0.847\n",
      "step 4000 ->, train: 0.515, val internal : 0.528, auc select: 0.818, auc bench: 0.818\n",
      "step 4050 ->, train: 0.543, val internal : 0.519, auc select: 0.814, auc bench: 0.814\n",
      "step 4100 ->, train: 0.556, val internal : 0.519, auc select: 0.822, auc bench: 0.822\n",
      "step 4150 ->, train: 0.532, val internal : 0.521, auc select: 0.832, auc bench: 0.832\n",
      "step 4200 ->, train: 0.487, val internal : 0.519, auc select: 0.836, auc bench: 0.836\n",
      "step 4250 ->, train: 0.507, val internal : 0.520, auc select: 0.825, auc bench: 0.825\n",
      "step 4300 ->, train: 0.503, val internal : 0.519, auc select: 0.835, auc bench: 0.835\n",
      "step 4350 ->, train: 0.521, val internal : 0.521, auc select: 0.841, auc bench: 0.841\n",
      "step 4400 ->, train: 0.506, val internal : 0.522, auc select: 0.838, auc bench: 0.838\n"
     ]
    }
   ],
   "source": [
    "accum_steps = 0\n",
    "batch_loss, batch_samples = 0, 0\n",
    "lr = opt_param['lr']\n",
    "\n",
    "train_setup = ledger.setdefault('train_setup', {})\n",
    "train_setup[step] = {\n",
    "    'transforms': transforms,\n",
    "    'data_setup': data_setup,\n",
    "    'optimizer': {\n",
    "        'name': opt,\n",
    "        'param': opt_param\n",
    "    },\n",
    "    'real_batch_size': real_batch_size,\n",
    "    'batch_split': batch_split\n",
    "}\n",
    "\n",
    "while lr:\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        _ = model.train()\n",
    "        \n",
    "        # Schedule sending to GPU(s)\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        # Update learning-rate, including stop training if over.\n",
    "        lr = model_setup.get_lr(step, supports=supports, base_lr=opt_param['lr'])\n",
    "        if lr is None: break\n",
    "        for param_group in optim.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        logits = model(x)\n",
    "        loss, n_samples = crit(logits, y)\n",
    "        if loss != 0:\n",
    "            # Accumulate grads\n",
    "            (loss / batch_split / n_samples).backward()\n",
    "\n",
    "        batch_loss += float(loss.data.cpu().numpy())  # Also ensures a sync point.\n",
    "        batch_samples += n_samples.cpu().numpy()\n",
    "\n",
    "        accum_steps += 1\n",
    "\n",
    "        # Update params\n",
    "        if accum_steps == batch_split:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            train_loss = batch_loss/batch_samples\n",
    "            ledger['train_loss'].append(train_loss)\n",
    "            batch_loss, batch_samples = 0, 0\n",
    "            ledger['lr'].append(lr)\n",
    "            step += 1\n",
    "            accum_steps = 0\n",
    "            \n",
    "            # Evaluate \n",
    "            if (step % eval_intervall) == 0:\n",
    "                preds, targets = evaluations.batch_prediction(model, valid_ext_loader)\n",
    "                auc_selection = evaluations.eval_auc(preds, targets, train_cols)\n",
    "                benchmark_cols = [i in ['Consolidation',  'Cardiomegaly', 'Atelectasis', 'Pleural Effusion', 'Edema'] for i in data.targets] \n",
    "                auc_bench = evaluations.eval_auc(preds, targets, benchmark_cols)\n",
    "                ledger['external'].append((step-1, auc_selection))\n",
    "                val = evaluations.eval_crit(model, valid_int_loader, crit)\n",
    "                ledger['internal'].append((step-1, val))\n",
    "                print(f'step {step} ->, train: {train_loss:.3f}, val internal : {val:.3f}, auc select: {auc_selection:.3f}, auc bench: {auc_bench:.3f}') # FULL: \n",
    "\n",
    "            if (step % save_intervall) == 0:\n",
    "                torch.save({\n",
    "                        \"step\": step,\n",
    "                        \"model\": model.module.state_dict(),\n",
    "                        \"optim\" : optim.state_dict(),\n",
    "                    }, \n",
    "                    os.path.join(model_out, f'step{step:05d}.pt')\n",
    "                )\n",
    "                json.dump(ledger, open(os.path.join(model_out, 'train_ledger.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        \"step\": step,\n",
    "        \"model\": model.module.state_dict(),\n",
    "        \"optim\" : optim.state_dict(),\n",
    "    }, \n",
    "    os.path.join(model_out, f'step{step:05d}.pt')\n",
    ")\n",
    "json.dump(ledger, open(os.path.join(model_out, 'train_ledger.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger['model'] = model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
